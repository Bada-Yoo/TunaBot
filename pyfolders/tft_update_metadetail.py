from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import os
import json

def extract_recommend_blocks(blocks, keyword):
    current_target = ""
    current_infos = []
    result = []

    for block in blocks:
        soup = BeautifulSoup(block.strip(), 'html.parser')
        span = soup.find("span")
        plain_text = soup.get_text(strip=True)

        if keyword in plain_text:
            if current_target and current_infos:
                result.append({
                    "target": current_target,
                    "info": current_infos
                })
                current_infos = []

            current_target = span.text.strip() if span else plain_text

        elif "í•©ë‹ˆë‹¤" in plain_text:
            # 'ì•„ì´í…œì¸' ë’¤ì— ê³µë°±ì´ ì—†ì„ ê²½ìš° ì¶”ê°€
            fixed_text = plain_text.replace("ì•„ì´í…œì¸", "ì•„ì´í…œì¸ ")
            current_infos.append(fixed_text)

    if current_target and current_infos:
        result.append({
            "target": current_target,
            "info": current_infos
        })

    return result

def crawl_detail_info():
    base_dir = os.path.dirname(__file__)
    meta_path = os.path.join(base_dir, "tft_meta.json")
    detail_path = os.path.join(base_dir, "tft_metadetail.json")

    with open(meta_path, "r", encoding="utf-8") as f:
        meta_data = json.load(f)

    detail_data = {"updated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"), "meta": []}

    options = webdriver.ChromeOptions()
    options.add_argument("--headless=chrome")
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-webgl")
    options.add_argument("--disable-software-rasterizer")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1280,3000")

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

    for entry in meta_data["meta"]:
        url = entry["url"]
        name = entry["name"]
        print(f"ğŸ” {name} ì„¸ë¶€ ì •ë³´ í¬ë¡¤ë§ ì¤‘...")

        try:
            driver.get(url)
            WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
        except:
            print(f"âŒ íƒ€ì„ì•„ì›ƒ: {url}")

        # ë‚œì´ë„
        try:
            difficulty_elem = driver.find_element(By.XPATH, "//h1[contains(text(), 'ë± ë‚œì´ë„')]/following-sibling::p")
            difficulty = difficulty_elem.text.strip()
        except:
            difficulty = ""

        # ìˆ˜ì§‘ ì•„ì´í…œ ì¶”ì²œ
        recommended_items = []
        try:
            section_elems = driver.find_elements(By.XPATH, "//h1[contains(text(), 'ìˆ˜ì§‘ ì•„ì´í…œ ì¶”ì²œ')]/following-sibling::p")
            blocks = []
            for p in section_elems:
                html = p.get_attribute("innerHTML")
                blocks += html.split("<br>")

            recommended_items += extract_recommend_blocks(blocks, "ë”œëŸ¬")
            recommended_items += extract_recommend_blocks(blocks, "íƒ±ì»¤")

        except Exception as e:
            print(f"âš ï¸ ìˆ˜ì§‘ ì•„ì´í…œ ì •ë³´ ì—†ìŒ: {e}")

        # ë ˆë²¨ë§ ì°¸ê³ 
        leveling = []
        try:
            p_tags = driver.find_elements(By.XPATH, "//h1[contains(text(), 'ìŠ¤í…Œì´ì§€ë³„ ë ˆë²¨ì—… ì¶”ì²œ')]/following-sibling::p")
            for p in p_tags:
                text = p.get_attribute("innerText").strip()
                if text:
                    lines = text.split("\n")
                    for line in lines:
                        if "(ì—°ìŠ¹ or ì—°íŒ¨)" in line:
                            line = line.replace("(ì—°ìŠ¹ or ì—°íŒ¨)", "").strip()
                        if line:
                            leveling.append(line)
        except Exception as e:
            print(f"âš ï¸ ë ˆë²¨ë§ ì •ë³´ ì—†ìŒ: {e}")

        detail_data["meta"].append({
            "index": entry["index"],
            "name": name,
            "difficulty": difficulty,
            "recommended_items": recommended_items,
            "leveling": leveling
        })

    driver.quit()

    with open(detail_path, "w", encoding="utf-8") as f:
        json.dump(detail_data, f, ensure_ascii=False, indent=2)
    print(f"âœ… metadetail.json ì €ì¥ ì™„ë£Œ ({detail_data['updated_at']} ê¸°ì¤€, {len(detail_data['meta'])}ê°œ ì¡°í•©)")

if __name__ == "__main__":
    crawl_detail_info()
